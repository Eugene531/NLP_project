# Описание

В этом репозитории представлен Telegram бот с встроенной системой обработки естественного языка (Natural Language Processing, NLP) для автоматического извлечения ключевых предложений из текстовых ответов на опросы. 

Бот: https://t.me/reccommendation_system_bot

![image](https://github.com/Eugene531/NLP_project/assets/62638634/0e6d8a8d-ae1b-4862-b92f-c7301bd45e5e)

# Структура проекта

NLP_project/

├── bot/                 # Модуль для бота

├── classifier/          # Модели и скрипты для классификации текстов

├── configs/classif/     # Конфигурационные файлы для классификации

├── database/            # Скрипты для работы с базой данных

├── summarizer/          # Модели и скрипты для суммаризации текстов

├── .gitattributes       # Файл атрибутов Git

├── README.md            # Файл с описанием проекта

├── main.py              # Главный скрипт для запуска проекта

└── requirements.txt     # Зависимости проекта

# Установка

1. Клонируйте репозиторий:

git clone https://github.com/Eugene531/NLP_project.git

2. Перейдите в директорию проекта:

cd NLP_project

3. Установите зависимости:

pip install -r requirements.txt



# Проблематика

- Процесс обработки и структурирования текстовых ответов на опросы с открытым ответов требует больших трудовых и временных затрат компании. 
- Трудности в анализе больших опросов и их некорректный анализ, приводит к  принятию неэффективных решений. 

# Наше решение

## Концептуальная схема проекта

![image](https://github.com/Eugene531/NLP_project/assets/62638634/38454e55-96b5-4b61-acbc-c25bc45b1a25)

## Прикладная схема проекта: 

![image](https://github.com/Eugene531/NLP_project/assets/62638634/a60ce5a3-2f06-439d-a196-74b82eadbc94)

# Технологии

## Используемые датасеты

- https://www.kaggle.com/datasets/alexandersemiletov/toxic-russian-comments/data
- https://github.com/yandex/geo-reviews-dataset-2023
- https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis

## Алгоритмы

- Модель BERT
- Классификация
- Суммаризатор

# Эффективность

## Метрики

1. Классификатор:

- Binary Cross-Entropy Loss;  
- Общий процент правильных предсказаний;  
- F1;  
- eval_precision - доля релевантных экземпляров среди всех, классифицированных как положительных.
  
2. Суммаризатор:
   
- косинусное сходство между исходным текстом и ключевыми словами.

## Начальная оценка точности модели

1. Классификатор:
   
- eval_loss: 0.15007872879505157;
- eval_accuracy: 0.94175;
- eval_f1: 0.9420253794476238;
- eval_precision: 0.9288518155053974.
  
2. Суммаризатор:
   
- Косинусное сходство: 0.61923

# Результаты

Для обучения и проверки работы моделей использовался датасет с комментариями пользователей ok.ru, которые промаркированы по уровню токсичности. Для решения задачи классификации использовалась предобученная модель BERT. Изначально эта модель была обучена на «маскированной языковой модели».




