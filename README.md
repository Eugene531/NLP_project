В этом репозитории представлен Telegram бот с встроенной системой обработки естественного языка (Natural Language Processing, NLP) для автоматического извлечения ключевых предложений из текстовых ответов на опросы. 

# Проблематика

- Процесс обработки и структурирования текстовых ответов на опросы с открытым ответов требует больших трудовых и временных затрат компании. 
- Трудности в анализе больших опросов и их некорректный анализ, приводит к  принятию неэффективных решений. 

# Наше решение

## Концептуальная схема проекта

![image](https://github.com/Eugene531/NLP_project/assets/62638634/38454e55-96b5-4b61-acbc-c25bc45b1a25)

## Прикладная схема проекта: 

![image](https://github.com/Eugene531/NLP_project/assets/62638634/a60ce5a3-2f06-439d-a196-74b82eadbc94)

# Технологии

## Используемые датасеты

- https://www.kaggle.com/datasets/alexandersemiletov/toxic-russian-comments/data
- https://github.com/yandex/geo-reviews-dataset-2023
- https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis

## Алгоритмы

- Модель BERT
- Классификация
- Суммаризатор

# Эффективность

## Метрики

1. Классификатор:

- Binary Cross-Entropy Loss;  
- Общий процент правильных предсказаний;  
- F1;  
- eval_precision - доля релевантных экземпляров среди всех, классифицированных как положительных.
  
2. Суммаризатор:
   
- косинусное сходство между исходным текстом и ключевыми словами.

## Начальная оценка точности модели

1. Классификатор:
   
- eval_loss: 0.15007872879505157;
- eval_accuracy: 0.94175;
- eval_f1: 0.9420253794476238;
- eval_precision: 0.9288518155053974.
  
3. Суммаризатор:
   
- Косинусное сходство: 0.61923

# Результаты

Для обучения и проверки работы моделей использовался датасет с комментариями пользователей ok.ru, которые промаркированы по уровню токсичности. Для решения задачи классификации использовалась предобученная модель BERT. Изначально эта модель была обучена на «маскированной языковой модели».
